{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Kinho's Homelab Series Documentation","text":"<p>Warning</p> <p>This documentation is currently in early stages and may be incomplete or subject to breaking changes. As with any homelab, there is a lot of experimentation, so some components might be unfinished or may change unexpectedly. If you plan to replicate this setup, please proceed with caution.</p>"},{"location":"#what-is-this","title":"What is this?","text":"<p>This is the documentation for my homelab series, it outlines the different components and their purpose for the k3s homelab cluster that might not be covered in the story form of the homelab series.</p>"},{"location":"apps/","title":"Apps","text":"<p>A list of all the apps running in the cluster.</p>"},{"location":"architecture/","title":"Architecture","text":"<p>\ud83d\udea7WIP</p>"},{"location":"cilium/","title":"Cilium","text":"<p>Cilium is the container network interface of choice for the cluster. It provides a lot of advantages from other CNI such as Flannel that come shipped in with K3s.</p>"},{"location":"gitops/","title":"GitOps","text":"<p>ArgoCD is used as the declarative continuous delivery solution for the cluster. Based on the GitOps workflow, it provides:</p> <ul> <li>Git as the source of truth for the state of the cluster</li> <li>Automated application life cycle management with easy rollbacks and updates</li> <li>Declarative app of apps pattern for easy deployment.</li> </ul>"},{"location":"gitops/#setup","title":"Setup","text":"<p>To setup argo, we need to apply all its CRDs, and create a new namespace with the following command:</p> <pre><code>kubectl create namespace argocd\nkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n</code></pre> <p>Then, you can extract the initial password for the admin user from the secret <code>argocd-initial-admin-secret</code>.</p> <pre><code>kubectl get secret argocd-initial-admin-secret -n argocd -ojsonpath='{.data.password}' | base64 -d\n</code></pre> <p>To quickly check the Argo UI, we can port forward the argocd server</p> <pre><code>kubectl port-forward svc/argocd-server -n argocd 8080:443\n</code></pre>"},{"location":"hardware/","title":"Hardware","text":"<ul> <li>VAIO VPCEH: Core i3 2310M, 4GB SDRAM DDR3, and 512GB HDD</li> <li>Lenovo PC: Core i3, 6GB RAM, 100GB HDD</li> </ul>"},{"location":"infisical/","title":"Infisical","text":"<p>Infisical is the software we use for managing secrets within the cluster. It follows the external secrets operator principle outlined in architecture.</p>"},{"location":"infisical/#setup","title":"Setup","text":"<p>To get infisical up and running, we need to configure an authentication method. The one with less friction would be the universalAuth where you simply create a secret that contains the clientId and the clientSecret. A more robust approach can also be implemented using Kubernetes Authentication.</p> <p>First, we head over to project access control in our infisical dashboard, and create a new machine identity.</p> <p></p> <p>We get a client id and then you can create a client secret by clicking on <code>add client secret</code> button.</p> <p></p> <p>Lastly, we run the following command to create the secret in the cluster for the insifical operator to authenticate.</p> <pre><code>kubectl create generic universal-auth-credentials --from-literal=clientId=\"&lt;your-identity-client-id&gt;\" --from-literal=clientSecret=\"your-identity-client-secret&gt;\"\n</code></pre> <p>The operator will pick up the secret, and we will be able to export our secrets with the custom CRDs. For example, to fetch an infisical secret we can use the InfisicalSecret CRD as follows.</p> <pre><code>apiVersion: secrets.infisical.com/v1alpha1\nkind: InfisicalSecret\nmetadata:\n  name: my-infisical-secret\nspec:\n  authentication:\n    universalAuth:\n      secretsScope:\n        projectSlug: &lt;the-project-slug&gt;\n\n        envSlug: \"\" # \"dev\", \"staging\", \"prod\"\n        secretsPath: \"\" # target a specific secrets path\n      credentialsRef:\n        secretName: universal-auth-credentials\n        secretNamespace: \"\" # the namespace where the auth secret resides\n\n  managedKubeSecretReferences:\n    - secretName: my-secret # the name that the managed secret should have\n      secretNamespace: \"\" # the namespace where the managed secret should reside\n</code></pre> <p>Additionally you can customize the structure of the secret by using template:</p> <pre><code>managedKubeSecretReferences:\n  - secretName: my-secret # the name that the managed secret should have\n    secretNamespace: \"\" # the namespace where the managed secret should reside\n    template:\n    includeAllSecrets: true\n    data:\n    NEW_KEY_NAME: \"{{ .KEY.SecretPath }} {{ .KEY.Value }}\"\n    KEY_WITH_BINARY_VALUE: \"{{ .KEY.SecretPath }} {{ .KEY.Value }}\"\n</code></pre>"},{"location":"k3s/","title":"K3s","text":"<p>\ud83d\udea7 WIP</p>"},{"location":"series/","title":"The Homelab Series","text":"<p>The progress of the homelab is documented in story telling fashion through my blog.</p>"},{"location":"storage/","title":"Storage","text":""},{"location":"tailscale/","title":"Tailscale","text":"<p>Tailscale serves as the VPN mesh for all the nodes in the cluster.</p> <ul> <li>Remote SSH access to all the nodes in the server</li> </ul>"},{"location":"tailscale/#setting-up-tailscale","title":"Setting up tailscale","text":"<p>Install the tailscale daemon on Linux with the following command.</p> <pre><code>curl -fsSL https://tailscale.com/install.sh | sh\n</code></pre> <p>Then, launch the daemon with ssh enabled as follows:</p> <pre><code>tailscale up --ssh\n</code></pre>"}]}